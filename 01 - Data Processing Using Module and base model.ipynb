{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to use methods from FraudKagglePreProcessData module to process train or test data.  Saves result as a df and as a pickled file for easy loading later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-05 13:29:29.878206 load_and_merge_data...\n",
      "df shape: (506691, 432)\n",
      "2019-09-05 13:29:54.997928 process_dates...\n",
      "2019-09-05 13:29:59.549813 process_device_names...\n",
      "2019-09-05 13:30:07.063725 get_lists_of_numerical_categorical...\n",
      "2019-09-05 13:30:07.064722 convert_numerical_categorical_to_strings...\n",
      "2019-09-05 13:30:17.540899 impute_missing_values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-05 13:30:49.385464 reduce_columns_with_PCA...\n",
      "2019-09-05 13:31:04.011893 assign_low_freq_values_as_other_in_df...\n",
      "df shape: (506691, 125)\n",
      "2019-09-05 13:34:59.123403 scale_numerical_fields...\n",
      "2019-09-05 13:35:05.619743 one_hot_encode_and_merge_with_numerical...\n",
      "df shape: (506691, 1182)\n",
      "2019-09-05 13:35:11.403272 reduce_mem_usage...\n",
      "Memory usage of properties dataframe is : 841.9541463851929  MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  700.8544340133667  MB\n",
      "This is  83.24140180583264 % of the initial size\n",
      "2019-09-05 13:35:46.299778 reconcile_features_from_test_to_train...\n",
      "2019-09-05 13:36:31.761861 pickle_df_and_columns...\n",
      "time taken: 0:07:06.908495\n"
     ]
    }
   ],
   "source": [
    "from FraudKagglePreProcessData import PreProcessData\n",
    "from datetime import datetime\n",
    "def process_data(transaction_path,identity_path,name,isTrain,model_feature_path=None):\n",
    "    start=datetime.now()\n",
    "    print(str(datetime.now())+' load_and_merge_data...')\n",
    "    df,labels  = PreProcessData.load_and_merge_data(transaction_path,identity_path,isTrain=isTrain)\n",
    "    print('df shape: ' + str(df.shape))\n",
    "    \n",
    "    print(str(datetime.now())+' process_dates...')\n",
    "    df = PreProcessData.process_dates(df)\n",
    "    \n",
    "    print(str(datetime.now())+' process_device_names...')\n",
    "    df = PreProcessData.process_device_names(df)\n",
    "    \n",
    "    print(str(datetime.now())+' get_lists_of_numerical_categorical...')\n",
    "    numerical,categorical = PreProcessData.get_lists_of_numerical_categorical(df,'ProductCD|card[1-6]|addr\\d|\\w_emaildomain|M[1-9]|time_|Device\\w+|id_12|id_13|id_14|id_15|id_16|id_17|id_18|id_19|id_20|id_21|id_22|id_23|id_24|id_25|id_26|id_27|id_28|id_29|id_30|id_31|id_32|id_33|id_34|id_35|id_36|id_37|id_38')\n",
    "    \n",
    "    print(str(datetime.now())+' convert_numerical_categorical_to_strings...')\n",
    "    df = PreProcessData.convert_numerical_categorical_to_strings(df,'ProductCD|card[1-6]|addr\\d|\\w_emaildomain|M[1-9]|time_|Device\\w+|id_12|id_13|id_14|id_15|id_16|id_17|id_18|id_19|id_20|id_21|id_22|id_23|id_24|id_25|id_26|id_27|id_28|id_29|id_30|id_31|id_32|id_33|id_34|id_35|id_36|id_37|id_38')\n",
    "    \n",
    "    print(str(datetime.now())+' impute_missing_values...')\n",
    "    df = PreProcessData.impute_missing_values(df,numerical,categorical)\n",
    "    \n",
    "    print(str(datetime.now())+' reduce_columns_with_PCA...')\n",
    "    df,numerical,categorical = PreProcessData.reduce_columns_with_PCA(df,'^V.*',30,numerical,categorical)\n",
    "    \n",
    "    print(str(datetime.now())+' assign_low_freq_values_as_other_in_df...')\n",
    "    df = PreProcessData.assign_low_freq_values_as_other_in_df(df,50,categorical)\n",
    "    print('df shape: ' + str(df.shape))\n",
    "    \n",
    "    print(str(datetime.now())+' scale_numerical_fields...')\n",
    "    df = PreProcessData.scale_numerical_fields(df,numerical)\n",
    "    \n",
    "    print(str(datetime.now())+' one_hot_encode_and_merge_with_numerical...')\n",
    "    df = PreProcessData.one_hot_encode_and_merge_with_numerical(df,numerical,categorical,labels,isTrain)\n",
    "    print('df shape: ' + str(df.shape))\n",
    "    \n",
    "    print(str(datetime.now())+' reduce_mem_usage...')\n",
    "    df,NAs = PreProcessData.reduce_mem_usage(df)\n",
    "          \n",
    "    if isTrain == False:\n",
    "        print(str(datetime.now())+' reconcile_features_from_test_to_train...')\n",
    "        df = PreProcessData.reconcile_features_from_test_to_train(df,model_feature_path)\n",
    "    \n",
    "    print(str(datetime.now())+' pickle_df_and_columns...')\n",
    "    PreProcessData.pickle_df_and_columns(df,name,isTrain)\n",
    "    finish=datetime.now()\n",
    "    print('time taken: '+str(finish-start))\n",
    "    return df\n",
    "#train = process_data('./data/raw/train_transaction_med.csv','./data/raw/train_identity_med.csv','train_med_processed',isTrain=True)\n",
    "#validate = process_data('./data/raw/test_transaction_med.csv','./data/raw/test_identity_med.csv','test_med_processed',isTrain=False,model_feature_path='./data/processed/train_med_processed_feature_names.pkl')\n",
    "\n",
    "#train = process_data('./data/raw/train_transaction.csv','./data/raw/train_identity.csv','train__processed',isTrain=True)\n",
    "validate = process_data('./data/raw/test_transaction.csv','./data/raw/test_identity.csv','test_processed',isTrain=False,model_feature_path='./data/processed/train_processed_feature_names.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create base model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.loc[:, train.columns != 'isFraud'], train['isFraud'], test_size=0.2,random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42,n_estimators = 10, max_depth=25)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob=rf.predict_proba(X_test)\n",
    "y_pred=rf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"ROC area under:\",metrics.roc_auc_score(y_test, y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on validate data with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 842 and input n_features is 531 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d30c91280ab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    386\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 842 and input n_features is 531 "
     ]
    }
   ],
   "source": [
    "y_pred=rf.predict_proba(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search CV on train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 500}</td>\n",
       "      <td>1.195341</td>\n",
       "      <td>0.958123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 500}</td>\n",
       "      <td>1.144995</td>\n",
       "      <td>0.958123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 1000}</td>\n",
       "      <td>2.388538</td>\n",
       "      <td>0.953047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 1000}</td>\n",
       "      <td>1.940876</td>\n",
       "      <td>0.953047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 10}</td>\n",
       "      <td>0.035347</td>\n",
       "      <td>0.791869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 10}</td>\n",
       "      <td>0.038656</td>\n",
       "      <td>0.791869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    params  mean_fit_time  mean_test_score\n",
       "1   {'max_depth': 25, 'n_estimators': 500}       1.195341         0.958123\n",
       "4   {'max_depth': 50, 'n_estimators': 500}       1.144995         0.958123\n",
       "2  {'max_depth': 25, 'n_estimators': 1000}       2.388538         0.953047\n",
       "5  {'max_depth': 50, 'n_estimators': 1000}       1.940876         0.953047\n",
       "0    {'max_depth': 25, 'n_estimators': 10}       0.035347         0.791869\n",
       "3    {'max_depth': 50, 'n_estimators': 10}       0.038656         0.791869"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "param = {'n_estimators': [10,500,1000],\n",
    "        'max_depth': [25,50]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1,scoring='roc_auc')\n",
    "gs_fit = gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_)[['params','mean_fit_time','mean_test_score']].sort_values('mean_test_score', ascending=False)\n",
    "#grid_results=[]\n",
    "#grid_results = pd.concat([grid_results,pd.DataFrame(gs_fit.cv_results_)]).sort_values('mean_test_score', ascending=False)\n",
    "#grid_results = pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "#grid_results.to_pickle(\"./grid_search_results.pkl\")\n",
    "#grid_results[['params','mean_fit_time','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          test:   1.7MiB\n",
      "                         train: 538.5KiB\n",
      "                       X_train: 414.2KiB\n",
      "                        X_test: 103.8KiB\n",
      "                        y_pred:   7.9KiB\n",
      "                       y_train:   3.5KiB\n",
      "        RandomForestClassifier:   2.0KiB\n",
      "                           _i2:   1.8KiB\n",
      "                           _i1:   1.8KiB\n",
      "                           _i6:   1.8KiB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
